{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38862da7",
   "metadata": {},
   "source": [
    "# Wildfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# required 3.12 version\n",
    "if [sys.version_info[i] for i in range(3)][:2] != [3, 12]: \n",
    "    raise Exception(f\"Python 3.12 is required (Current is {[sys.version_info[i] for i in range(3)]})\")\n",
    "\n",
    "# import time\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import cv2\n",
    "# import imutils\n",
    "# import PIL\n",
    "from PIL import Image\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "import numpy\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb218385",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROGRAM_NAME: str = \"Wildfire\"\n",
    "COLUMNS = [\"ImagePath\", \"Image\", \"Inferred\", \"Class\"]\n",
    "CATEGORIES: list[str] = [\"fire\", \"nofire\"]\n",
    "DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "__file__ = os.getcwd()\n",
    "BASE_DIR = Path(__file__).resolve().parent / PROGRAM_NAME\n",
    "DATA_DIR: Path = BASE_DIR / \"data\"\n",
    "pandas.set_option('display.max_colwidth', 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8dd9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_path_or_else(base: Path, paths: list[str]) -> Path:\n",
    "    for path in paths:\n",
    "        maybe_path = base / path\n",
    "        if maybe_path.is_dir():\n",
    "            return maybe_path\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fc05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(folder_path: Path) -> DataFrame:\n",
    "    print(f\"[{PROGRAM_NAME}]: Generating new dataframe from '{folder_path.relative_to(BASE_DIR)}'\", end=\" \")\n",
    "    \n",
    "    FIRE_DIR: Path = append_path_or_else(folder_path, [\"fire\", \"wildfire\"])\n",
    "    NOFIRE_DIR: Path = append_path_or_else(folder_path, [\"nofire\", \"nowildfire\"])\n",
    "    \n",
    "    fire_images: list[tuple[Path, str, bool, str]] = [\n",
    "        (img.relative_to(BASE_DIR), img.name, False, \"fire\") for img in FIRE_DIR.iterdir() if img.is_file()\n",
    "    ]\n",
    "    nofire_images: list[tuple[Path, str, bool, str]] = [\n",
    "        (img.relative_to(BASE_DIR), img.name, False, \"nofire\") for img in NOFIRE_DIR.iterdir() if img.is_file()\n",
    "    ]\n",
    "\n",
    "    data: list[tuple[Path, str, bool, str]] = fire_images + nofire_images\n",
    "    dataframe: DataFrame = DataFrame(data, columns=COLUMNS)\n",
    "    \n",
    "    print(dataframe.shape)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f081e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe_npz(folder_path: Path):\n",
    "    print(f\"[{PROGRAM_NAME}]: Generating new dataframe from '{folder_path.relative_to(BASE_DIR)}'\", end=\" \")\n",
    "    \n",
    "    data: list[tuple[Path, str, bool, str]] = []\n",
    "        \n",
    "    for npz_file_path in folder_path.iterdir():\n",
    "        with numpy.load(npz_file_path) as npz_data:\n",
    "            infer_label = \"fire\" if numpy.any(npz_data[\"label\"] == 1) else \"nofire\"\n",
    "            data.append((npz_file_path.relative_to(BASE_DIR), npz_file_path.name, True, infer_label))\n",
    "\n",
    "    dataframe: DataFrame = DataFrame(data, columns=COLUMNS)\n",
    "    \n",
    "    print(dataframe.shape)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b6b28",
   "metadata": {},
   "source": [
    "Image Dataset 1: `jafar_2023`\n",
    "> Ibn Jafar, Anam; Islam, Al Mohimanul ; Binta Masud, Fatiha; Ullah, Jeath Rahmat; Ahmed, Md. Rayhan (2023), “FlameVision : A new dataset for wildfire classification and detection using aerial imagery ”, Mendeley Data, V4. https://doi.org/10.17632/fgvscdjsmt.4\n",
    "\n",
    "Image Dataset 2: `madafri_2023`\n",
    "> El-Madafri I, Peña M, Olmedo-Torre N. The Wildfire Dataset: Enhancing Deep Learning-Based Forest Fire Detection with a Diverse Evolving Open-Source Dataset Focused on Data Representativeness and a Novel Multi-Task Learning Approach. Forests. 2023; 14(9):1697. https://doi.org/10.3390/f14091697\n",
    "\n",
    "Image Dataset 3: `aaba_2022`\n",
    "> Aaba, A. (2022). Wildfire Prediction Dataset (Satellite Images) [Data set]. Kaggle. https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset/data\n",
    "\n",
    "Image Dataset 4: `xu_2024`\n",
    "> Xu, Y., Berg, A., & Haglund, L. (2024, March 26). Sen2Fire: A Challenging Benchmark Dataset for Wildfire Detection using Sentinel Data. https://doi.org/10.5281/zenodo.10881058 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10646dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#                                                #\n",
    "#  When you download all datasets:               #\n",
    "#    1. Renamed parent folders `lastname_year`.  #\n",
    "#    2. Keep the file structure unmodified.      #\n",
    "#                                                #\n",
    "##################################################\n",
    "\n",
    "'''\n",
    "Wildfire\n",
    "├───wildfire.ipynb\n",
    "└───data\n",
    "    ├───aaba_2022\n",
    "    │   ├───test\n",
    "    │   │   ├───nowildfire\n",
    "    │   │   └───wildfire\n",
    "    │   ├───train\n",
    "    │   │   ├───nowildfire\n",
    "    │   │   └───wildfire\n",
    "    │   └───valid\n",
    "    │       ├───nowildfire\n",
    "    │       └───wildfire\n",
    "    ├───jafar_2023\n",
    "    │   ├───Classification\n",
    "    │   │   ├───test\n",
    "    │   │   │   ├───fire\n",
    "    │   │   │   └───nofire\n",
    "    │   │   ├───train\n",
    "    │   │   │   ├───fire\n",
    "    │   │   │   └───nofire\n",
    "    │   │   └───valid\n",
    "    │   │       ├───fire\n",
    "    │   │       └───nofire\n",
    "    │   └───Detection\n",
    "    │       ├───test\n",
    "    │       │   ├───annotations\n",
    "    │       │   └───images\n",
    "    │       ├───train\n",
    "    │       │   ├───annotations\n",
    "    │       │   └───images\n",
    "    │       └───valid\n",
    "    │           ├───annotations\n",
    "    │           └───images\n",
    "    ├───madafri_2023\n",
    "    │   ├───test\n",
    "    │   │   ├───fire\n",
    "    │   │   └───nofire\n",
    "    │   ├───train\n",
    "    │   │   ├───fire\n",
    "    │   │   └───nofire\n",
    "    │   └───val\n",
    "    │       ├───fire\n",
    "    │       └───nofire\n",
    "    └───xu_2024\n",
    "        ├───scene1\n",
    "        ├───scene2\n",
    "        ├───scene3\n",
    "        └───scene4\n",
    "'''\n",
    "\n",
    "class WildFireData1():\n",
    "    def __init__(self) -> None:\n",
    "        self.DATASET_NAME = \"jafar_2023\"\n",
    "        self.DIR: Path = DATA_DIR / self.DATASET_NAME\n",
    "        self.CLASS_DIR: Path = self.DIR / \"Classification\"\n",
    "        self.CLASS_TRAIN_DIR: Path = self.CLASS_DIR / \"train\"\n",
    "        self.CLASS_TEST_DIR: Path = self.CLASS_DIR / \"test\"\n",
    "        self.CLASS_VALID_DIR: Path = self.CLASS_DIR / \"valid\"\n",
    "        self.DETECTION_DIR: Path = self.DIR / \"Detection\"\n",
    "        self.DETECTION_TRAIN_DIR: Path = self.DETECTION_DIR / \"train\"\n",
    "        self.DETECTION_TEST_DIR: Path = self.DETECTION_DIR / \"test\"\n",
    "        self.DETECTION_VALID_DIR: Path = self.DETECTION_DIR / \"valid\"\n",
    "    \n",
    "    def generate_dataframes(self) -> list[DataFrame]:\n",
    "        return [\n",
    "            generate_dataframe(self.CLASS_TRAIN_DIR),\n",
    "            generate_dataframe(self.CLASS_TEST_DIR),\n",
    "            generate_dataframe(self.CLASS_VALID_DIR),\n",
    "        ]\n",
    "\n",
    "class WildFireData2():\n",
    "    def __init__(self) -> None:\n",
    "        self.DATASET_NAME = \"madafri_2023\"\n",
    "        self.DIR: Path = DATA_DIR / self.DATASET_NAME\n",
    "        self.TRAIN_DIR: Path = self.DIR / \"train\"\n",
    "        self.TEST_DIR: Path = self.DIR / \"test\"\n",
    "        self.VALID_DIR: Path = self.DIR / \"val\"\n",
    "    \n",
    "    def generate_dataframes(self) -> list[DataFrame]:\n",
    "        return [\n",
    "            generate_dataframe(self.TRAIN_DIR),\n",
    "            generate_dataframe(self.TEST_DIR),\n",
    "            generate_dataframe(self.VALID_DIR),\n",
    "        ]\n",
    "\n",
    "class WildFireData3():\n",
    "    def __init__(self) -> None:\n",
    "        self.DATASET_NAME = \"aaba_2022\"\n",
    "        self.DIR: Path = DATA_DIR / self.DATASET_NAME\n",
    "        self.TRAIN_DIR: Path = self.DIR / \"train\"\n",
    "        self.TEST_DIR: Path = self.DIR / \"test\"\n",
    "        self.VALID_DIR: Path = self.DIR / \"valid\"\n",
    "    \n",
    "    def generate_dataframes(self) -> list[DataFrame]:\n",
    "        return [\n",
    "            generate_dataframe(self.TRAIN_DIR),\n",
    "            generate_dataframe(self.TEST_DIR),\n",
    "            generate_dataframe(self.VALID_DIR),\n",
    "        ]\n",
    "\n",
    "class WildFireData4():\n",
    "    def __init__(self) -> None:\n",
    "        self.DATASET_NAME = \"xu_2024\"\n",
    "        self.DIR: Path = DATA_DIR / self.DATASET_NAME\n",
    "        self.SCENE_1_DIR: Path = self.DIR / \"scene1\"\n",
    "        self.SCENE_2_DIR: Path = self.DIR / \"scene2\"\n",
    "        self.SCENE_3_DIR: Path = self.DIR / \"scene3\"\n",
    "        self.SCENE_4_DIR: Path = self.DIR / \"scene4\"\n",
    "    \n",
    "    def generate_dataframes(self) -> list[DataFrame]:\n",
    "        dataframe_100 = pandas.concat(\n",
    "            [\n",
    "                generate_dataframe_npz(self.SCENE_1_DIR),\n",
    "                generate_dataframe_npz(self.SCENE_2_DIR),\n",
    "                generate_dataframe_npz(self.SCENE_3_DIR),\n",
    "                generate_dataframe_npz(self.SCENE_4_DIR),\n",
    "            ],\n",
    "            ignore_index = True\n",
    "        )\n",
    "        \n",
    "        random_num = 69 # random state for reproducibility\n",
    "        dataframe_70 = dataframe_100.sample(frac=0.70, random_state=random_num) \n",
    "        dataframe_30 = dataframe_100.drop(dataframe_70.index)\n",
    "        dataframe_15_1 = dataframe_30.sample(frac=0.50, random_state=random_num)\n",
    "        dataframe_15_2 = dataframe_30.drop(dataframe_15_1.index)\n",
    "             \n",
    "        return [\n",
    "            dataframe_70,\n",
    "            dataframe_15_1,\n",
    "            dataframe_15_2,\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcfc050e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Wildfire]: Generating new dataframe from 'data\\jafar_2023\\Classification\\train' (6800, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\jafar_2023\\Classification\\test' (900, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\jafar_2023\\Classification\\valid' (900, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\madafri_2023\\train' (1887, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\madafri_2023\\test' (410, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\madafri_2023\\val' (403, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\aaba_2022\\train' (30250, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\aaba_2022\\test' (6300, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\aaba_2022\\valid' (6300, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\xu_2024\\scene1' (864, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\xu_2024\\scene2' (594, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\xu_2024\\scene3' (504, 4)\n",
      "[Wildfire]: Generating new dataframe from 'data\\xu_2024\\scene4' (504, 4)\n"
     ]
    }
   ],
   "source": [
    "wildfire_data_1: WildFireData1 = WildFireData1()\n",
    "wildfire_data_2: WildFireData2 = WildFireData2()\n",
    "wildfire_data_3: WildFireData3 = WildFireData3()\n",
    "wildfire_data_4: WildFireData4 = WildFireData4()\n",
    "\n",
    "dataframe_partials: list[list[DataFrame]] = [\n",
    "    wildfire_data_1.generate_dataframes(),\n",
    "    wildfire_data_2.generate_dataframes(),\n",
    "    wildfire_data_3.generate_dataframes(),\n",
    "    wildfire_data_4.generate_dataframes(),\n",
    "]\n",
    "\n",
    "dataframe_train_partials: list[DataFrame] = [dataframe_partial[0] for dataframe_partial in dataframe_partials]\n",
    "dataframe_test_partials: list[DataFrame] = [dataframe_partial[1] for dataframe_partial in dataframe_partials]\n",
    "dataframe_valid_partials: list[DataFrame] = [dataframe_partial[2] for dataframe_partial in dataframe_partials]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56e19e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ImagePath                   Image  Inferred   Class\n",
      "0      data\\jafar_2023\\Clas...            fire (1).png     False    fire\n",
      "1      data\\jafar_2023\\Clas...           fire (10).png     False    fire\n",
      "2      data\\jafar_2023\\Clas...          fire (100).png     False    fire\n",
      "3      data\\jafar_2023\\Clas...         fire (1000).png     False    fire\n",
      "4      data\\jafar_2023\\Clas...         fire (1001).png     False    fire\n",
      "...                        ...                     ...       ...     ...\n",
      "40658  data\\xu_2024\\scene4\\...  scene_4_patch_21_9.npz      True    fire\n",
      "40659  data\\xu_2024\\scene1\\...  scene_1_patch_29_6.npz      True  nofire\n",
      "40660  data\\xu_2024\\scene2\\...  scene_2_patch_9_25.npz      True  nofire\n",
      "40661  data\\xu_2024\\scene1\\...  scene_1_patch_8_26.npz      True  nofire\n",
      "40662  data\\xu_2024\\scene3\\...  scene_3_patch_14_3.npz      True  nofire\n",
      "\n",
      "[40663 rows x 4 columns]\n",
      "\n",
      "┌────────────┬─────────────┬───────┐\n",
      "│   Images   │    Count    │   %   │\n",
      "├────────────┼─────────────┼───────┤\n",
      "│  Training  │ 40663/56616 │ 0.72% │\n",
      "├────────────┼─────────────┼───────┤\n",
      "│  Testing   │ 7980/56616  │ 0.14% │\n",
      "├────────────┼─────────────┼───────┤\n",
      "│ Validation │ 7973/56616  │ 0.14% │\n",
      "└────────────┴─────────────┴───────┘\n"
     ]
    }
   ],
   "source": [
    "dataframe_train: DataFrame = pandas.concat(dataframe_train_partials, ignore_index=True)\n",
    "dataframe_test: DataFrame = pandas.concat(dataframe_test_partials, ignore_index=True)\n",
    "dataframe_valid: DataFrame = pandas.concat(dataframe_valid_partials, ignore_index=True)\n",
    "\n",
    "print(dataframe_train)\n",
    "\n",
    "train_count: int = dataframe_train.shape[0]\n",
    "test_count: int = dataframe_test.shape[0]\n",
    "valid_count: int = dataframe_valid.shape[0]\n",
    "total_count: int = train_count + test_count + valid_count\n",
    "train_percent: float = round(train_count/total_count, 2)\n",
    "test_percent: float = round(test_count/total_count, 2)\n",
    "valid_percent: float = round(valid_count/total_count, 2)\n",
    "info_table = tabulate(\n",
    "    [\n",
    "        [\"Images\", \"Count\", \"%\"],\n",
    "        [\"Training\", f\"{train_count}/{total_count}\", f\"{train_percent}%\"],\n",
    "        [\"Testing\", f\"{test_count}/{total_count}\", f\"{test_percent}%\"],\n",
    "        [\"Validation\", f\"{valid_count}/{total_count}\", f\"{valid_percent}%\"],\n",
    "    ],\n",
    "    headers=\"firstrow\",\n",
    "    tablefmt=\"simple_grid\",\n",
    "    numalign=\"center\",\n",
    "    stralign=\"center\",\n",
    ")\n",
    "\n",
    "print()\n",
    "print(info_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize per band to [0, 255]\n",
    "def norm(x):\n",
    "    x = x.astype(numpy.float32)\n",
    "    x -= x.min()\n",
    "    x /= (x.max() - x.min() + 1e-6)\n",
    "    return (x * 255).astype(numpy.uint8)\n",
    "\n",
    "def reconstruct_npz(file_path: Path) -> Image.Image | None:\n",
    "    if file_path.is_file():\n",
    "        with numpy.load(file_path) as npz_data: # image, aerosol, label\n",
    "            image_label_data = npz_data[\"image\"]\n",
    "            # select RGB bands (B4, B3, B2)\n",
    "            red = image_label_data[3]\n",
    "            green = image_label_data[2]\n",
    "            blue = image_label_data[1]                \n",
    "            rgb = numpy.stack([red, green, blue], axis=-1)\n",
    "            rgb = numpy.dstack([norm(red), norm(green), norm(blue)])\n",
    "            return Image.fromarray(rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
